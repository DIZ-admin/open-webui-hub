name: ğŸ§ª Automated Testing Suite

on:
  schedule:
    # Ğ—Ğ°Ğ¿ÑƒÑĞº ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ² 02:00 UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - integration
          - performance
          - security
      environment:
        description: 'Environment to test'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

env:
  PYTHON_VERSION: '3.12'
  NODE_VERSION: '20'

jobs:
  # ============================================================================
  # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ ÑÑ€ĞµĞ´Ñ‹
  # ============================================================================
  setup-test-environment:
    name: ğŸ—ï¸ Setup Test Environment
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.matrix.outputs.tests }}
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ¯ Determine test matrix
        id: matrix
        run: |
          case "${{ github.event.inputs.test_type || 'all' }}" in
            "integration")
              echo "tests=[\"integration\"]" >> $GITHUB_OUTPUT
              ;;
            "performance")
              echo "tests=[\"performance\", \"ab_testing\"]" >> $GITHUB_OUTPUT
              ;;
            "security")
              echo "tests=[\"security\", \"vulnerability\"]" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "tests=[\"integration\", \"performance\", \"ab_testing\", \"functional\", \"security\"]" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: ğŸ” Validate test scripts
        run: |
          echo "ğŸ” Validating test scripts..."
          python -m py_compile tests/*.py
          echo "âœ… All test scripts are valid"

  # ============================================================================
  # Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
  # ============================================================================
  integration-testing:
    name: ğŸ”— Integration Testing
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: contains(fromJson(needs.setup-test-environment.outputs.test-matrix), 'integration')
    strategy:
      matrix:
        service: [openwebui, docling, tika, ollama, litellm, searxng]
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: ğŸ³ Start test environment
        run: |
          # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ env Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
          for env_file in env/*.example; do
            if [ -f "$env_file" ]; then
              cp "$env_file" "${env_file%.example}.env"
            fi
          done
          
          # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹
          docker-compose -f compose.local.yml up -d ${{ matrix.service }}

      - name: â³ Wait for service readiness
        run: |
          timeout 300 bash -c '
            case "${{ matrix.service }}" in
              "openwebui")
                until curl -f http://localhost:3000/health; do sleep 5; done
                ;;
              "docling")
                until curl -f http://localhost:5001/health; do sleep 5; done
                ;;
              "tika")
                until curl -f http://localhost:9998/tika; do sleep 5; done
                ;;
              "ollama")
                until curl -f http://localhost:11434/api/tags; do sleep 5; done
                ;;
              "litellm")
                until curl -f http://localhost:4000/health; do sleep 5; done
                ;;
              "searxng")
                until curl -f "http://localhost:8888/search?q=test"; do sleep 5; done
                ;;
            esac
          '

      - name: ğŸ§ª Run service-specific tests
        run: |
          echo "ğŸ§ª Running tests for ${{ matrix.service }}..."
          python tests/integration_testing.py --service ${{ matrix.service }}

      - name: ğŸ“Š Generate test report
        if: always()
        run: |
          python tests/report_generator.py --service ${{ matrix.service }}

      - name: ğŸ“¤ Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-${{ matrix.service }}
          path: |
            tests/reports/
            tests/*_results_*.json

      - name: ğŸ›‘ Cleanup
        if: always()
        run: docker-compose -f compose.local.yml down

  # ============================================================================
  # ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
  # ============================================================================
  performance-testing:
    name: âš¡ Performance Testing
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: contains(fromJson(needs.setup-test-environment.outputs.test-matrix), 'performance')
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: ğŸ³ Start full environment
        run: |
          # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° env Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
          for env_file in env/*.example; do
            if [ -f "$env_file" ]; then
              cp "$env_file" "${env_file%.example}.env"
            fi
          done
          
          docker-compose -f compose.local.yml up -d

      - name: â³ Wait for all services
        run: |
          timeout 600 bash -c '
            until curl -f http://localhost:3000/health && \
                  curl -f http://localhost:5001/health && \
                  curl -f http://localhost:9998/tika; do
              sleep 10
            done
          '

      - name: âš¡ Run performance tests
        run: |
          echo "âš¡ Running performance tests..."
          python tests/ab_testing_framework.py --duration 300 --concurrent 10

      - name: ğŸ“Š Generate performance report
        if: always()
        run: |
          python tests/comprehensive_report_generator.py

      - name: ğŸ“ˆ Performance analysis
        run: |
          echo "ğŸ“ˆ Analyzing performance metrics..."
          # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
          if [ -f tests/ab_testing_results_*.json ]; then
            python -c "
            import json, glob
            files = glob.glob('tests/ab_testing_results_*.json')
            if files:
                with open(files[-1]) as f:
                    data = json.load(f)
                    print(f'Average response time: {data.get(\"avg_response_time\", \"N/A\")}ms')
                    print(f'Success rate: {data.get(\"success_rate\", \"N/A\")}%')
                    print(f'Requests per second: {data.get(\"requests_per_second\", \"N/A\")}')
            "
          fi

      - name: ğŸ“¤ Upload performance results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-test-results
          path: |
            tests/reports/
            tests/*_results_*.json
            tests/*_report_*.md

      - name: ğŸ›‘ Cleanup
        if: always()
        run: docker-compose -f compose.local.yml down

  # ============================================================================
  # A/B Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
  # ============================================================================
  ab-testing:
    name: ğŸ”„ A/B Testing
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: contains(fromJson(needs.setup-test-environment.outputs.test-matrix), 'ab_testing')
    strategy:
      matrix:
        scenario: [docling_vs_tika, different_models, load_patterns]
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: ğŸ”„ Run A/B test scenario
        run: |
          echo "ğŸ”„ Running A/B test: ${{ matrix.scenario }}"
          python tests/run_ab_testing.py --scenario ${{ matrix.scenario }}

      - name: ğŸ“Š Generate A/B test report
        if: always()
        run: |
          python tests/comprehensive_report_generator.py --scenario ${{ matrix.scenario }}

      - name: ğŸ“¤ Upload A/B test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: ab-test-${{ matrix.scenario }}
          path: |
            tests/reports/
            tests/*_results_*.json

  # ============================================================================
  # Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
  # ============================================================================
  functional-testing:
    name: ğŸ¯ Functional Testing
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: contains(fromJson(needs.setup-test-environment.outputs.test-matrix), 'functional')
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: ğŸ³ Start environment
        run: |
          for env_file in env/*.example; do
            if [ -f "$env_file" ]; then
              cp "$env_file" "${env_file%.example}.env"
            fi
          done
          docker-compose -f compose.local.yml up -d

      - name: â³ Wait for services
        run: |
          timeout 300 bash -c '
            until curl -f http://localhost:3000/health; do sleep 5; done
          '

      - name: ğŸ¯ Run functional tests
        run: |
          echo "ğŸ¯ Running functional tests..."
          python tests/functional_web_testing.py

      - name: ğŸ“¤ Upload functional test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: functional-test-results
          path: |
            tests/functional_web_testing_results_*.json

      - name: ğŸ›‘ Cleanup
        if: always()
        run: docker-compose -f compose.local.yml down

  # ============================================================================
  # Ğ¡Ğ²Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚
  # ============================================================================
  generate-summary:
    name: ğŸ“‹ Generate Test Summary
    runs-on: ubuntu-latest
    needs: [integration-testing, performance-testing, ab-testing, functional-testing]
    if: always()
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“¥ Download all test results
        uses: actions/download-artifact@v3

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install matplotlib seaborn pandas jinja2

      - name: ğŸ“Š Generate comprehensive summary
        env:
          GITHUB_EVENT_INPUTS_ENVIRONMENT: ${{ github.event.inputs.environment || 'staging' }}
          GITHUB_EVENT_INPUTS_TEST_TYPE: ${{ github.event.inputs.test_type || 'all' }}
        run: |
          echo "ğŸ“Š Generating comprehensive test summary..."
          python -c "
          import json, glob, os
          from datetime import datetime
          
          # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ¾Ğ²
          results = {}
          for artifact_dir in glob.glob('*/'):
              for json_file in glob.glob(f'{artifact_dir}*.json'):
                  try:
                      with open(json_file) as f:
                          data = json.load(f)
                          results[json_file] = data
                  except:
                      pass
          
          # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑĞ²Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚
          summary = {
              'timestamp': datetime.now().isoformat(),
              'total_tests': len(results),
              'environment': os.environ.get('GITHUB_EVENT_INPUTS_ENVIRONMENT', 'staging'),
              'test_type': os.environ.get('GITHUB_EVENT_INPUTS_TEST_TYPE', 'all'),
              'results': results
          }
          
          with open('test_summary.json', 'w') as f:
              json.dump(summary, f, indent=2)
          
          print(f'Generated summary with {len(results)} test results')
          "

      - name: ğŸ“¤ Upload test summary
        uses: actions/upload-artifact@v3
        with:
          name: test-summary
          path: test_summary.json

      - name: ğŸ“¢ Post summary comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('test_summary.json')) {
              const summary = JSON.parse(fs.readFileSync('test_summary.json', 'utf8'));
              const comment = `## ğŸ§ª Automated Test Summary
              
              **Environment:** ${summary.environment}
              **Test Type:** ${summary.test_type}
              **Total Tests:** ${summary.total_tests}
              **Timestamp:** ${summary.timestamp}
              
              âœ… All automated tests completed successfully!
              
              ğŸ“Š Detailed results are available in the workflow artifacts.`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
